# PyTermBot
# 🧠 CLI Chatbot with Mistral via Ollama

A simple and efficient command-line chatbot powered by the Mistral model running locally through [Ollama](https://ollama.com/). Type your queries right into your terminal and receive fast, intelligent responses with zero cloud latency.

## 🚀 Features
- Local LLM interaction with Mistral
- Summarization, Q&A, or text generation
- Fully customizable CLI interface
- No internet needed after setup

## 🛠️ Tech Stack
- **Python 3.x**
- **Ollama** (Local LLM hosting)
- **Mistral** (Language model)
- Optionally: JavaScript frontend or shell wrappers

## 📦 Installation

1. Install Python and Ollama from [Ollama's website](https://ollama.com/)
2. Pull the model:
   ```bash
   ollama pull mistral

